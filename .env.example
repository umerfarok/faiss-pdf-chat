# Example environment file - Copy this to .env and update with your own values

# API Keys (Replace with your actual keys)
OPENAI_API_KEY=your-openai-api-key-here
GROQ_API_KEY=your-groq-api-key-here-if-needed

# PDF Processing Configuration
PDF_FOLDER=./database/
VECTOR_STORE_PATH=./vectorstore/

# Set to "true" to automatically sync PDFs at startup, "false" to use existing vector store
SYNC_FOLDER_DATA=true

# Chunking Configuration
CHUNK_SIZE=2000
CHUNK_OVERLAP=200

# Model Configuration
# For embeddings, options: 
# - text-embedding-ada-002 (OpenAI default)
# - text-embedding-3-small (Higher quality, same dimensions)
# - text-embedding-3-large (Highest quality, higher dimensions)
EMBEDDING_MODEL=text-embedding-3-small

# For chat completion, options:
# - gpt-3.5-turbo (Faster, less expensive)
# - gpt-4-turbo (Stronger reasoning, more expensive)
# - gpt-4o (Latest model with strong performance)
CHAT_MODEL=gpt-3.5-turbo

# For intent classification:
# - gpt-3.5-turbo (Recommended, fast and efficient for this task)
INTENT_CLASSIFICATION_MODEL=gpt-3.5-turbo

# Maximum tokens to generate in chat response
MAX_TOKENS=1000

# Temperature (0.0 = deterministic, 1.0 = creative)
TEMPERATURE=0.2

# Search Configuration
TOP_K_RESULTS=6

# --- Phishing Classification ---
# HuggingFace model name for phishing detection
PHISHING_MODEL_NAME=Abdelllm2025/phishing_clf_fine_tuned_bert
# Set to "true" to enable the phishing classifier, "false" to disable
ENABLE_PHISHING_CLASSIFIER=true
# Set to "true" to use OpenAI for intent classification, "false" for rule-based
USE_AI_INTENT_CLASSIFICATION=true

# GPU Acceleration (if available)
# Options: "true" or "false" - enables GPU for FAISS if available
USE_GPU=false
GPU_DEVICE_ID=0

# FAISS Index Type:
# - "flat" (most accurate but slow for large collections)
# - "hnsw" (faster search with minimal accuracy loss)
# - "ivf" (faster but less accurate)
FAISS_INDEX_TYPE=flat

# Advanced FAISS parameters (only relevant when using non-flat indices)
# Number of lists/clusters for IVF
IVF_NLIST=100
# Number of neighbors for HNSW
HNSW_M=32
# Number of layers for HNSW
HNSW_EF_CONSTRUCTION=200
# Number of candidates to consider during search
HNSW_EF_SEARCH=128

# Performance tuning
# Number of documents to process in parallel
PARALLEL_PROCESSING=4
# Batch size for embeddings
EMBEDDING_BATCH_SIZE=32
